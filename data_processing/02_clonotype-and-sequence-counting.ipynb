{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clonotype and sequence counting\n",
    "\n",
    "Starting with deduplicated clonotypes or sequences, count the occurrence of repeatedly observed clonotypes/sequences (seen in multiple biological replicates from the same year) or shared clonotypes/sequences (seen in multiple years).\n",
    "\n",
    "The [`abutils`](https://www.github.com/briney/abutils) Python package is required, and can be installed by running `pip install abutils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from abutils.utils.jobs import monitor_mp_jobs\n",
    "from abutils.utils.pipeline import list_files, make_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files and directories\n",
    "\n",
    "There are two input data directories each for clonotypes and sequences -- one containing deduplicated single-year pools (to quantify repeatedly observed clonotypes/sequences) and another containing deduplicated cross-year pools (to quantify shared clonotypes/sequences). The input data used by the following code is too large to be included in this repository. Input datasets can be generated using the code in [**this Jupyter notebook**](LINK). Alternatively, data can be downloaded from the following links:\n",
    "  * single-year clonotype data can be downloaded [**here**](LINK)\n",
    "  * cross-year clonotype data can be downloaded [**here**](LINK)\n",
    "  * single-year sequence data can be downloaded [**here**](LINK)\n",
    "  * cross-year sequence data can be downloaded [**here**](LINK)\n",
    "\n",
    "If generating the input data using the code in the referenced Jupyter notebook, the data should be deposited into the appropriate directory. If downloading the data, either decompress the downloaded data file in the appropriate directory or modify the `single_year_dir` and/or `cross_year_dir` variables as needed.\n",
    "\n",
    "***NOTE:*** *The uncompressed cross-year input data is quite large (>2TB for clonotypes and >20TB for sequences). Ensure that you have sufficient storage before downloading and decompressing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "single_year_clonotype_dir = './data/dedup_year_clonotype_pools/'\n",
    "cross_year_clonotype_dir = './data/dedup_cross-year_clonotype_pools/'\n",
    "clonotype_output_dir = './data/user-calculated_cross-year_clonotype_duplicate-counts/'\n",
    "single_year_sequence_dir = './data/dedup_year_sequence_pools/'\n",
    "cross_year_sequence_dir = './data/dedup_cross-year_sequence_pools/'\n",
    "sequence_output_dir = './data/user-calculated_cross-year_sequence_duplicate-counts/'\n",
    "make_dir(clonotype_output_dir)\n",
    "make_dir(sequence_output_dir)\n",
    "\n",
    "# files\n",
    "clonotype_files = [f for f in list_files(single_year_clonotype_dir) if 'pool_vj-aa_with-counts.txt' in f]\n",
    "clonotype_files += [f for f in list_files(cross_year_clonotype_dir) if 'pool_vj-aa_with-counts.txt' in f]\n",
    "sequence_files = [f for f in list_files(single_year_sequence_dir) if 'pool_vdj-nt_with-counts.txt' in f]\n",
    "sequence_files += [f for f in list_files(cross_year_sequence_dir) if 'pool_vdj-nt_with-counts.txt' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clonotypes\n",
    "clonotype_files_by_year_count = {i: [] for i in range(1, 5)}\n",
    "for f in clonotype_files:\n",
    "    num = len(os.path.basename(f).split('_')[0].split('-'))/2\n",
    "    clonotype_files_by_year_count[num].append(f)\n",
    "\n",
    "# sequences\n",
    "sequence_files_by_year_count = {i: [] for i in range(1, 5)}\n",
    "for f in clonotype_files:\n",
    "    num = len(os.path.basename(f).split('_')[0].split('-'))/2\n",
    "    sequence_files_by_year_count[num].append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate counting\n",
    "\n",
    "Now we'd like to count the duplicate (repeatedly observed or shared) clonotypes for every groupwise combination of our 3 years. Each group can contain one or more years, meaning the total number of possible groupwise combinations is quite large. We'll use the `multiprocessing` package to parallelize the process which should speed things up substantially, although even with parallelization, this will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_duplicates(input_file, output_dir):\n",
    "    counts = {str(i): 0 for i in range(1, 7)}\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            c = line.strip().split()[0]\n",
    "            counts[c] += 1\n",
    "    year_prefix = os.path.basename(input_file).split('_')[0]\n",
    "    output_file = os.path.join(output_dir, '{}_occurrence-counts.txt'.format(year_prefix))\n",
    "    with open(output_file, 'w') as f:\n",
    "        data = ['{}\\t{}'.format(k, v) for k, v in sorted(counts.items(), key=lambda x: int(x[0]))]\n",
    "        data_string = '\\n'.join(data)\n",
    "        f.write(data_string) \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clonotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year count: 1\n",
      "(4/4) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "(4/4) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "\n",
      "\n",
      "\n",
      "year count: 2\n",
      "(6/6) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "(6/6) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "\n",
      "\n",
      "\n",
      "year count: 3\n",
      "(4/4) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "(4/4) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "\n",
      "\n",
      "\n",
      "year count: 4\n",
      "(1/1) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "(1/1) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = mp.Pool(maxtasksperchild=1)\n",
    "clonotype_counts = {}\n",
    "\n",
    "for num in clonotype_files_by_year_count.keys():\n",
    "    \n",
    "    async_results = []\n",
    "    print('year count:', num)\n",
    "    sys.stdout.flush()\n",
    "    for ifile in clonotype_files_by_year_count[num]:\n",
    "        async_results.append(p.apply_async(count_duplicates, args=(ifile, clonotype_output_dir)))\n",
    "    monitor_mp_jobs(async_results)\n",
    "    clonotype_counts[num] = [ar.get() for ar in async_results]\n",
    "    print('\\n')\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year count: 1\n",
      "(4/4) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "(4/4) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "\n",
      "\n",
      "\n",
      "year count: 2\n",
      "(6/6) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "(6/6) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "\n",
      "\n",
      "\n",
      "year count: 3\n",
      "(4/4) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "(4/4) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "\n",
      "\n",
      "\n",
      "year count: 4\n",
      "(1/1) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "(1/1) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = mp.Pool(maxtasksperchild=1)\n",
    "sequence_counts = {}\n",
    "\n",
    "for num in sequence_files_by_year_count.keys():\n",
    "    async_results = []\n",
    "    print('year count:', num)\n",
    "    sys.stdout.flush()\n",
    "    for ifile in sequence_files_by_year_count[num]:\n",
    "        async_results.append(p.apply_async(count_duplicates, args=(ifile, sequence_output_dir)))\n",
    "    monitor_mp_jobs(async_results)\n",
    "    sequence_counts[num] = [ar.get() for ar in async_results]\n",
    "    print('\\n')\n",
    "p.close()\n",
    "p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
