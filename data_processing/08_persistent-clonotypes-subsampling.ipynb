{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistent clonotype and sequence fraction subsampling\n",
    "\n",
    "In this notebook we will calculate the percent of shared clonotypes and sequences verses sample depth. Subsample sizes range from 1000 to 1,000,000 sequences per biological replicate.\n",
    "\n",
    "The [`abutils`](https://www.github.com/briney/abutils) Python package is required for this notebook, and can be installed by running `pip install abutils`.\n",
    "\n",
    "*NOTE: this notebook requires the use of the Unix command line tool `shuf`. Thus, it requires a Unix-based operating system to run correctly (MacOS and most flavors of Linux should be fine). Running this notebook on Windows 10 may be possible using the [Windows Subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/about) but we have not tested this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from collections import Counter\n",
    "import os\n",
    "import subprocess as sp\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from abutils.utils.pipeline import make_dir, list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dir('./data/persistent-clonotypes/')\n",
    "make_dir('./data/persistent-sequences/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling clonotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "10000\n",
      "100000\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "infile1='./data/dedup_year-merged_vj-aa/D103-2016/D103-2016_dedup_pool_vj-aa.txt'\n",
    "infile2='./data/dedup_year-merged_vj-aa/D103-2021/D103-2021_dedup_pool_vj-aa.txt'\n",
    "\n",
    "persistent_number={}\n",
    "for subsample_count in [1000, 10000, 100000, 200000, 400000, 600000, 800000, 1000000]:\n",
    "    print(subsample_count)\n",
    "    persistent_number[str(subsample_count)]=[]\n",
    "    for i in range(10):\n",
    "        shuf_cmd1 = 'shuf -n {} {}'.format(str(subsample_count), infile1)\n",
    "        p = sp.Popen(shuf_cmd1, stdout=sp.PIPE, stderr=sp.PIPE, shell=True, encoding='utf8')\n",
    "        stdout1, stderr1 = p.communicate()\n",
    "\n",
    "        shuf_cmd2 = 'shuf -n {} {}'.format(str(subsample_count), infile2)\n",
    "        p = sp.Popen(shuf_cmd2, stdout=sp.PIPE, stderr=sp.PIPE, shell=True, encoding='utf8')\n",
    "        stdout2, stderr2 = p.communicate()\n",
    "\n",
    "        tp1_clonotype_subsample=stdout1.split('\\n')[:-1]\n",
    "        tp2_clonotype_subsample=stdout2.split('\\n')[:-1]\n",
    "\n",
    "        clone_counts=Counter(tp1_clonotype_subsample+tp2_clonotype_subsample)\n",
    "\n",
    "        persistent_clones=[c for c in clone_counts if clone_counts[c]==2]\n",
    "        persistent_number[str(subsample_count)].append(len(persistent_clones))\n",
    "\n",
    "with open(f'./data/persistent-clonotypes/D103-{str(subsample_count)}subsample-{str(i)}', 'w') as file:\n",
    "    file.write('\\n'.join(persistent_clones))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata=[]\n",
    "for i in persistent_number.keys():\n",
    "    data=persistent_number[i]\n",
    "    data=[_i/int(i) for _i in data]\n",
    "    intervals=st.t.interval(0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    pdata.append({'size':i, \n",
    "                  'average': np.mean(data)*100, \n",
    "                  'upper': intervals[1]*100, \n",
    "                  'lower': intervals[0]*100})\n",
    "pdf=pd.DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.to_csv('./data/persistent-clonotypes/D103-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile1='./data/dedup_year-merged_vj-aa/327059-2016/327059-2016_dedup_pool_vj-aa.txt'\n",
    "infile2='./data/dedup_year-merged_vj-aa/327059-2020/327059-2020_dedup_pool_vj-aa.txt'\n",
    "\n",
    "persistent_number={}\n",
    "for subsample_count in [1000, 10000, 100000, 200000, 400000, 600000, 800000, 1000000]:\n",
    "    print(subsample_count)\n",
    "    persistent_number[str(subsample_count)]=[]\n",
    "    for i in range(10):\n",
    "        shuf_cmd1 = 'shuf -n {} {}'.format(str(subsample_count), infile1)\n",
    "        p = sp.Popen(shuf_cmd1, stdout=sp.PIPE, stderr=sp.PIPE, shell=True, encoding='utf8')\n",
    "        stdout1, stderr1 = p.communicate()\n",
    "\n",
    "        shuf_cmd2 = 'shuf -n {} {}'.format(str(subsample_count), infile2)\n",
    "        p = sp.Popen(shuf_cmd2, stdout=sp.PIPE, stderr=sp.PIPE, shell=True, encoding='utf8')\n",
    "        stdout2, stderr2 = p.communicate()\n",
    "\n",
    "        tp1_clonotype_subsample=stdout1.split('\\n')[:-1]\n",
    "        tp2_clonotype_subsample=stdout2.split('\\n')[:-1]\n",
    "\n",
    "        clone_counts=Counter(tp1_clonotype_subsample+tp2_clonotype_subsample)\n",
    "\n",
    "        persistent_clones=[c for c in clone_counts if clone_counts[c]==2]\n",
    "        persistent_number[str(subsample_count)].append(len(persistent_clones))\n",
    "\n",
    "with open(f'./data/persistent-clonotypes/327059-{str(subsample_count)}subsample-{str(i)}', 'w') as file:\n",
    "    file.write('\\n'.join(persistent_clones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata=[]\n",
    "for i in persistent_number.keys():\n",
    "    data=persistent_number[i]\n",
    "    data=[_i/int(i) for _i in data]\n",
    "    intervals=st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    pdata.append({'size':i, \n",
    "                  'average': np.mean(data)*100, \n",
    "                  'upper': intervals[1]*100, \n",
    "                  'lower': intervals[0]*100})\n",
    "pdf=pd.DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.to_csv('./data/persistent-clonotypes/327059-df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "10000\n",
      "100000\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "infile1='./data/dedup_year-merged_nt-seq/D103-2016/D103-2016_dedup_pool_nt-seq.txt'\n",
    "infile2='./data/dedup_year-merged_nt-seq/D103-2021/D103-2021_dedup_pool_nt-seq.txt'\n",
    "\n",
    "persistent_number={}\n",
    "for subsample_count in [1000, 10000, 100000, 200000, 400000, 600000, 800000, 1000000]:\n",
    "    print(subsample_count)\n",
    "    persistent_number[str(subsample_count)]=[]\n",
    "    for i in range(10):\n",
    "        shuf_cmd1 = 'shuf -n {} {}'.format(str(subsample_count), infile1)\n",
    "        p = sp.Popen(shuf_cmd1, stdout=sp.PIPE, stderr=sp.PIPE, shell=True, encoding='utf8')\n",
    "        stdout1, stderr1 = p.communicate()\n",
    "\n",
    "        shuf_cmd2 = 'shuf -n {} {}'.format(str(subsample_count), infile2)\n",
    "        p = sp.Popen(shuf_cmd2, stdout=sp.PIPE, stderr=sp.PIPE, shell=True, encoding='utf8')\n",
    "        stdout2, stderr2 = p.communicate()\n",
    "\n",
    "        tp1_clonotype_subsample=stdout1.split('\\n')[:-1]\n",
    "        tp2_clonotype_subsample=stdout2.split('\\n')[:-1]\n",
    "\n",
    "        clone_counts=Counter(tp1_clonotype_subsample+tp2_clonotype_subsample)\n",
    "\n",
    "        persistent_clones=[c for c in clone_counts if clone_counts[c]==2]\n",
    "        persistent_number[str(subsample_count)].append(len(persistent_clones))\n",
    "\n",
    "with open(f'./data/persistent-clonotypes/D103-{str(subsample_count)}subsample-{str(i)}', 'w') as file:\n",
    "    file.write('\\n'.join(persistent_clones))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata=[]\n",
    "for i in persistent_number.keys():\n",
    "    data=persistent_number[i]\n",
    "    data=[_i/int(i) for _i in data]\n",
    "    intervals=st.t.interval(0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    pdata.append({'size':i, \n",
    "                  'average': np.mean(data)*100, \n",
    "                  'upper': intervals[1]*100, \n",
    "                  'lower': intervals[0]*100})\n",
    "pdf=pd.DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.to_csv('./data/persistent-sequences/D103-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile1='./data/dedup_year-merged_nt-seq/327059-2016/327059-2016_dedup_pool_nt-seq.txt'\n",
    "infile2='./data/dedup_year-merged_nt-seq/327059-2020/327059-2020_dedup_pool_nt-seq.txt'\n",
    "\n",
    "persistent_number={}\n",
    "for subsample_count in [1000, 10000, 100000, 200000, 400000, 600000, 800000, 1000000]:\n",
    "    print(subsample_count)\n",
    "    persistent_number[str(subsample_count)]=[]\n",
    "    for i in range(10):\n",
    "        shuf_cmd1 = 'shuf -n {} {}'.format(str(subsample_count), infile1)\n",
    "        p = sp.Popen(shuf_cmd1, stdout=sp.PIPE, stderr=sp.PIPE, shell=True, encoding='utf8')\n",
    "        stdout1, stderr1 = p.communicate()\n",
    "\n",
    "        shuf_cmd2 = 'shuf -n {} {}'.format(str(subsample_count), infile2)\n",
    "        p = sp.Popen(shuf_cmd2, stdout=sp.PIPE, stderr=sp.PIPE, shell=True, encoding='utf8')\n",
    "        stdout2, stderr2 = p.communicate()\n",
    "\n",
    "        tp1_clonotype_subsample=stdout1.split('\\n')[:-1]\n",
    "        tp2_clonotype_subsample=stdout2.split('\\n')[:-1]\n",
    "\n",
    "        clone_counts=Counter(tp1_clonotype_subsample+tp2_clonotype_subsample)\n",
    "\n",
    "        persistent_clones=[c for c in clone_counts if clone_counts[c]==2]\n",
    "        persistent_number[str(subsample_count)].append(len(persistent_clones))\n",
    "\n",
    "with open(f'./data/persistent-clonotypes/327059-{str(subsample_count)}subsample-{str(i)}', 'w') as file:\n",
    "    file.write('\\n'.join(persistent_clones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata=[]\n",
    "for i in persistent_number.keys():\n",
    "    data=persistent_number[i]\n",
    "    data=[_i/int(i) for _i in data]\n",
    "    intervals=st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    pdata.append({'size':i, \n",
    "                  'average': np.mean(data)*100, \n",
    "                  'upper': intervals[1]*100, \n",
    "                  'lower': intervals[0]*100})\n",
    "pdf=pd.DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.to_csv('./data/persistent-sequences/327059-df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
